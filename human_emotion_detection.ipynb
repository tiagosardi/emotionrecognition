{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "human_emotion_detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiagosardi/emotionrecognition/blob/main/human_emotion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG91ueXbo_iP"
      },
      "source": [
        "!git clone  https://github.com/tiagosardi/emotionrecognition.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvbknSweQRAH"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_b5mPd5Qr56"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVd0bfL9PLAv"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVsRFaCzRSIJ"
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKWBZVHHRk3C"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff-rBJVJTK9R"
      },
      "source": [
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWcD7op3LsZS"
      },
      "source": [
        "!unzip train.csv.zip -d train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqm7wGHNLu_w"
      },
      "source": [
        "!unzip test.csv.zip -d test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q35rMhnfQCiP"
      },
      "source": [
        "!tar -vzxf fer2013.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YMJ2L-9Tuj_"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xRYbz6bBNKP"
      },
      "source": [
        "data = pd.read_csv('fer2013/fer2013.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w_junKmSsLv"
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6epqK1x_SwH6"
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.hist(data['emotion'], bins= 30)\n",
        "plt.title('Img X emotions')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2dOPU9iTHsH"
      },
      "source": [
        "height, width = 48,48\n",
        "faces = []\n",
        "samples = 0\n",
        "for pixel_sequence in  pixels:\n",
        "  face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "  face = np.asarray(face).reshape(height,width)\n",
        "  faces.append(face)\n",
        "\n",
        "  if(samples<10):\n",
        "    cv2_imshow(face)\n",
        "  amostras+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9OKwnL0QSQa"
      },
      "source": [
        "X_train, X_test , y_train, y_test = train_test_split(faces, emocoes, test_size = .1, random_state = 42)\n",
        "X_train, X_val ,y_train, y_val = train_test_split (X_train, y_train , test_size = .1, random_state = 41)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYueDhDDEwNr"
      },
      "source": [
        "print(\"Numero de imagens no conjunto de treinamento: \", len(X_train))\n",
        "print(\"Numero de imagens no conjunto de teste: \", len(X_test))\n",
        "print(\"Numero de imagens no conjunto de validacao: \", len(X_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjA6H8T6FDAd"
      },
      "source": [
        "np.save('mod_xtest' , X_test)\n",
        "np.save('mod_ytest', y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRmlPucGFs5s"
      },
      "source": [
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "width, height = 48,48\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MvcbmBDF-mS"
      },
      "source": [
        "model.compile (loss= 'categorical_crossentropy',\n",
        "               optimizer = Adam(lr=.001, beta_1=.9, beta_2= .999, epsilon=1e-7),\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "arquivo_modelo = 'modelo_01_expressoes.h5'\n",
        "arquivo_modelo_json = 'modelo_01_expressoes.json'\n",
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor = .9, patience=3, verbose = 1)\n",
        "early_stopper = EarlyStoppping(monitor='val_loss', min_delta=0,patience=8, verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(arquivo_modelo, monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMbVb8bOJ4rQ"
      },
      "source": [
        "history = model.fit(np.array(X_train), np.array(y_train),\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (np.array(X_val),np.array(y_val)),\n",
        "                    shuffle = True,\n",
        "                    callbacks = [lr_reducer, early_stopper, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}